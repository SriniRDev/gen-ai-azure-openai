{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs722OIpy3IO"
   },
   "source": [
    "# ASSISTANTS API\n",
    "\n",
    "This notebook demonstrates the use of the Assistants API from Azure OpenAI to create and interact with a custom AI assistant. The Assistants API enables the creation and management of conversational assistants with specific instructions and tools.\n",
    "\n",
    "Steps Covered:\n",
    "\n",
    "1. Assistant Creation: Define a new assistant by specifying its custom instructions and selecting a model. Tools like the Code Interpreter are enabled to enhance the assistant's capabilities.\n",
    "\n",
    "2. Thread Creation: Initialize a new conversation thread where interactions with the assistant will take place.\n",
    "\n",
    "3. Message Addition: Send messages to the thread, simulating user queries or prompts that the assistant will respond to.\n",
    "\n",
    "4. Running the Assistant: Execute the assistant on the thread to generate responses based on the provided instructions and user inputs. The notebook handles the response retrieval and displays the text content.\n",
    "\n",
    "5. Chat Completions API needs the full conversation to be passed as the body to OpenAI for getting the context but in Assitant API we just need to pass assitant id and thread id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsYxc-H_rRR6",
    "outputId": "a7c3fd3e-e164-4ecb-b2f3-b9bb71d34e50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./anaconda3/lib/python3.11/site-packages (1.40.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./anaconda3/lib/python3.11/site-packages (from openai) (3.5.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./anaconda3/lib/python3.11/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./anaconda3/lib/python3.11/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./anaconda3/lib/python3.11/site-packages (from openai) (0.5.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./anaconda3/lib/python3.11/site-packages (from openai) (1.10.8)\r\n",
      "Requirement already satisfied: sniffio in ./anaconda3/lib/python3.11/site-packages (from openai) (1.2.0)\r\n",
      "Requirement already satisfied: tqdm>4 in ./anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./anaconda3/lib/python3.11/site-packages (from openai) (4.12.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in ./anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\r\n",
      "Requirement already satisfied: certifi in ./anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hBHMLeGafim1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hs74-openai-test.openai.azure.com/\n",
      "https://hs74-openai-test.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Set up your environment variables for the Azure OpenAI endpoint and API key.\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv('../azureopenai.env')\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "print (azure_endpoint)\n",
    "print (azure_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RM1mUAIOfxjp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Initialize the Azure OpenAI client with environment variables for the endpoint, API key, and API version\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),                 \n",
    "  api_version=\"2024-05-01-preview\"\n",
    ")\n",
    "\n",
    "# Create a new assistant with specific instructions and tools\n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Math Tutor\",  # Name of the assistant\n",
    "  instructions=\"You are a personal maths tutor. Write and run code to answer maths questions.\",  # Instructions for the assistant\n",
    "  tools=[] , # Specify the tool to be used by the assistant ({\"type\": \"code_interpreter\"})\n",
    "model=\"gpt-4.1-mini-aoai\",  # Specify the deployment name to use\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.lib.azure.AzureOpenAI at 0x113014280>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GObnsO_mtgY3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/ylrfx2wd3mx5yrfd_xnp5vz80000gp/T/ipykernel_47968/1210653836.py:2: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
      "  thread = client.beta.threads.create()\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a new thread to hold the conversation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m thread \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#thread is an object type which contains a field id which is the unique identifier \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#of the conversation/thread we have created\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenv/gen-ai-az-openai/lib/python3.10/site-packages/typing_extensions.py:2956\u001b[0m, in \u001b[0;36mdeprecated.__call__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(arg)\n\u001b[1;32m   2954\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2955\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, category\u001b[38;5;241m=\u001b[39mcategory, stacklevel\u001b[38;5;241m=\u001b[39mstacklevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenv/gen-ai-az-openai/lib/python3.10/site-packages/openai/resources/beta/threads/threads.py:132\u001b[0m, in \u001b[0;36mThreads.create\u001b[0;34m(self, messages, metadata, tool_resources, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03mCreate a thread.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/threads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_resources\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthread_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mThreadCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mThread\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenv/gen-ai-az-openai/lib/python3.10/site-packages/openai/_base_client.py:1256\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1244\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1251\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1252\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1253\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1254\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1255\u001b[0m     )\n\u001b[0;32m-> 1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.virtualenv/gen-ai-az-openai/lib/python3.10/site-packages/openai/_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1043\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1044\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a new thread to hold the conversation\n",
    "thread = client.beta.threads.create()\n",
    "#thread is an object type which contains a field id which is the unique identifier \n",
    "#of the conversation/thread we have created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wg_6DRoPtn3L"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Send a message from the user to thread\n",
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,  # The ID of the thread to send the message to\n",
    "  role=\"user\",  # Role of the sender (user in this case)\n",
    "  content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"  # Content of the message\n",
    ")\n",
    "\n",
    "# Run the assistant to process the thread and respond\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=thread.id,  # The ID of the thread to run the assistant on\n",
    "  assistant_id=assistant.id,  # The ID of the assistant to use\n",
    "  instructions=\"Please give step by step explanation.\"  # Instructions for the assistant\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tReLd_-etpl_",
    "outputId": "6f6738c9-7041-4890-9a72-545a8bc5bbc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! I can help you solve the equation. \n",
      "\n",
      "Step 1: Start with the equation `3x + 11 = 14`.\n",
      "\n",
      "Step 2: To isolate the variable `x`, we want to get rid of the `11` on the left side of the equation. To do this, subtract `11` from both sides of the equation:\n",
      "\n",
      "   3x + 11 - 11 = 14 - 11\n",
      "\n",
      "Simplifying, we get:\n",
      "\n",
      "   3x = 3\n",
      "\n",
      "Step 3: Next, we need to solve for `x`. To do this, divide both sides of the equation by `3`:\n",
      "\n",
      "   (3x)/3 = 3/3\n",
      "\n",
      "Simplifying, we get:\n",
      "\n",
      "   x = 1\n",
      "\n",
      "Step 4: The solution to the equation `3x + 11 = 14` is `x = 1`.\n",
      "I need to solve the equation `3x + 11 = 14`. Can you help me?\n",
      "Sure! I can help you solve the equation. \n",
      "\n",
      "Step 1: Start with the equation `3x + 11 = 14`.\n",
      "\n",
      "Step 2: To isolate the variable `x`, we want to get rid of the `11` on the left side of the equation. To do this, subtract `11` from both sides of the equation.\n",
      "\n",
      "               3x + 11 - 11 = 14 - 11\n",
      "               3x = 3\n",
      "\n",
      "Step 3: Now we have the equation `3x = 3`. To solve for `x`, we need to get `x` by itself on one side of the equation. Since `3x` means `3` multiplied by `x`, we can divide both sides of the equation by `3`.\n",
      "\n",
      "               (3x)/3 = 3/3\n",
      "               x = 1\n",
      "\n",
      "Step 4: The solution to the equation `3x + 11 = 14` is `x = 1`.\n",
      "I need to solve the equation `3x + 11 = 14`. Can you help me?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the run status is 'completed'\n",
    "if run.status == 'completed':\n",
    "  # Fetch the list of messages from the thread\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id  # The ID of the thread to fetch messages from\n",
    "  )\n",
    "  # Extract and print the text content from the messages\n",
    "  for msg in messages.data:  # Iterate over each message in the list of messages\n",
    "        for content_block in msg.content:  # Iterate over each content block in the message\n",
    "            if content_block.type == 'text':  # Check if the content block is of type 'text'\n",
    "                print(content_block.text.value)  # Print the text content value\n",
    "else:\n",
    "  # Print the status of the run if it is not 'completed'\n",
    "  print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "4i-IJw8luy4B",
    "outputId": "98ed94bc-cf9c-4eb2-a1f8-1b164c4bd96b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question (or type 'exit' to quit): Solve 3x+2=26\n",
      "Assistant: Sure! I can help you solve the equation.\n",
      "\n",
      "Step 1: Start with the equation `3x + 2 = 26`.\n",
      "\n",
      "Step 2: To isolate the variable `x`, we want to get rid of the `2` on the left side of the equation. To do this, subtract `2` from both sides of the equation:\n",
      "\n",
      "   3x + 2 - 2 = 26 - 2\n",
      "\n",
      "Simplifying, we get:\n",
      "\n",
      "   3x = 24\n",
      "\n",
      "Step 3: Next, we need to solve for `x`. To do this, divide both sides of the equation by `3`:\n",
      "\n",
      "   (3x)/3 = 24/3\n",
      "\n",
      "Simplifying, we get:\n",
      "\n",
      "   x = 8\n",
      "\n",
      "Step 4: The solution to the equation `3x + 2 = 26` is `x = 8`.\n",
      "Enter your question (or type 'exit' to quit): Change +2 to -2 , show the equation and give the result\n",
      "Assistant: Sure! I can help you solve the equation `3x - 2 = 26`.\n",
      "\n",
      "The equation is: \n",
      "3x - 2 = 26\n",
      "\n",
      "To solve for `x`, follow these steps:\n",
      "\n",
      "Step 1: Add `2` to both sides of the equation to isolate the `3x` term:\n",
      "3x - 2 + 2 = 26 + 2\n",
      "3x = 28\n",
      "\n",
      "Step 2: Divide both sides of the equation by `3` to solve for `x`:\n",
      "(3x)/3 = 28/3\n",
      "x = 9.3333 (rounded to 4 decimal places)\n",
      "\n",
      "The solution to the equation `3x - 2 = 26` is `x = 9.3333`.\n",
      "Enter your question (or type 'exit' to quit): exit\n",
      "Exiting the chat.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"Enter your question (or type 'exit' to quit): \")\n",
    "\n",
    "    # Exit the loop if the user types 'exit'\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Exiting the chat.\")\n",
    "        break\n",
    "\n",
    "    # Send a message to the thread from the user\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,  # The ID of the thread to send the message to\n",
    "        role=\"user\",  # Role of the sender (user in this case)\n",
    "        content=user_input  # Content of the message from the user\n",
    "    )\n",
    "\n",
    "    # Run the assistant to process the thread and respond\n",
    "    run = client.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread.id,  # The ID of the thread to run the assistant on\n",
    "        assistant_id=assistant.id,  # The ID of the assistant to use\n",
    "        instructions=\"Give Step by Step explanation.\"  # Instructions for the assistant\n",
    "    )\n",
    "\n",
    "    # Check if the run status is 'completed'\n",
    "    if run.status == 'completed':\n",
    "        # Fetch the list of messages from the thread\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id  # The ID of the thread to fetch messages from\n",
    "        )\n",
    "        # Extract and print only the last message from the assistant\n",
    "        last_message = messages.data[0].content[0].text.value\n",
    "        print(\"Assistant:\", last_message)\n",
    "    else:\n",
    "        # Print the status of the run if it is not 'completed'\n",
    "        print(\"Run status:\", run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gen-ai-az-openai",
   "language": "python",
   "name": "gen-ai-az-openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
